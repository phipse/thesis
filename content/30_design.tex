\chapter{Design}
\label{sec:design}

% Ist das zentrale Kapitel der Arbeit. Hier werden das Ziel sowie die
% eigenen Ideen, Wertungen, Entwurfsentscheidungen vorgebracht. Es kann
% sich lohnen, verschiedene Möglichkeiten durchzuspielen und dann
% explizit zu begründen, warum man sich für eine bestimmte entschieden
% hat. Dieses Kapitel sollte - zumindest in Stichworten - schon bei den
% ersten Festlegungen eines Entwurfs skizziert werden.
% Es wird sich aber in einer normal verlaufenden
% Arbeit dauernd etwas daran ändern. Das Kapitel darf nicht zu
% detailliert werden, sonst langweilt sich der Leser. Es ist sehr
% wichtig, das richtige Abstraktionsniveau zu finden. Beim Verfassen
% sollte man auf die Wiederverwendbarkeit des Textes achten.

% Plant man eine Veröffentlichung aus der Arbeit zu machen, können von
% diesem Kapitel Teile genommen werden. Das Kapitel wird in der Regel
% wohl mindestens 8 Seiten haben, mehr als 20 können ein Hinweis darauf
% sein, daß das Abstraktionsniveau verfehlt wurde.


In this chapter, I describe the problems needing to be solved to achieve the
overall goal of a behaviour-aware load balancer on the Fiasco.OC microkernel.

In general, a load balancer assigns the currently running set of threads to the
available cores.
To that end, it observers the execution time requirements of all threads and
distributes the threads to all cores, such that each core processes an equal
share of the total work.
If the amount of work processed per core is uneven, the load balancer
needs to reestablish balance by selecting a thread to migrate from an
overloaded core to a less utilized core.
The load balancer must account for the underlying architecture, as
the performance improvement when migrating a thread from one \gls{smt} core to
its companion core, is likely smaller than migrating it to another physical core.

Besides execution time, cache affinity is also relevant to the load balancer.
Migrating a thread which has a lot of present cache lines will hurt its
performance, because the thread must load the necessary memory into the new
core's cache, before it can continue execution.

In case of an imbalance the load balancer selects threads to migrate, after
considering cache affinity and execution time requirements.
A load balancing interval is usually much larger than a scheduling interval.

From chapter \ref{sec:state} four relevant areas for a behvaiour-aware load
balancer can be deduced:
\gls{smt}, isolation, communication and energy.
After discussing these four areas, I explain the design of the load balancer
service, before I finish the chapter with a discussion about load and balance.

\input{content/31_smt.tex}
\input{content/33_isolation.tex}
%\input{content/35_behaviour.tex}
\input{content/37_communication.tex}
\input{content/36_energy.tex}
\input{content/34_balancer.tex}
\input{content/38_load.tex}
\input{content/39_summary.tex}

%\input{content/32_assumptions.tex}
%\todo{move assumptions to end of chapter}
 % ---------------------------------------------------------------------------
\begin {comment}
\begin{itemize}
  \item SMT
  \item Isolation
  \item Behaviour observation
  \item Communication
  \item ThreadMapper aka Scheduler Proxy \& TaskProxies
  \item Algorithms
\end{itemize}

* Table with data sources for prediction and analysis


\subsection{Scratchpad}
\paragraph{Idea:}
One question of the thesis is which information can I get
from the system and where does this information come from.
There are two kinds of information sources, static ones and dynamic ones.

\textbf{Static information sources} are things that can be questioned by the load
balancer and will return mostly the same answer.
E.g. scheduling parameters of a thread (prio, quantium, affinity),
the process\_ID of POSIX threads of the same task is equal,
\ldots{}.

\textbf{Dynamic information sources} are dependent on measurement and behaviour of the
threads and the system.
E.g. hardware performance counters,
usage of time during the last epoch,
\ldots{}.

Uncategorized: shared memory/dataspace sharing, can I even get this info?
IPC: let the threads pass a cap list of frequent comm partners:

\paragraph{Minimal Design}
The load balancing service must maintain its own representation for all threads
in the system and also for the hardware configuration, to be able to place
threads on different cores.
After initialization, where the service should query the kernel scheduler to
set up its data structures, it has to replace the Scheduler capability, to
transparently intervene in the scheduling process.
Hence, the service has to implement the L4\dots{}Scheduler Protocol.
However, newly created threads are started by calling
\begin{verbatim}
L4::Env::env()->Scheduler()->run_thread(
	      L4::Cap<L4::Thread>,
	      l4_sched_param_t);
\end{verbatim}
So the Scheduler-Cap in Env needs to be the capability of the load balancing
service.
To provide a scheduler to a task started by Ned, the start-up parameters
overwrite the default scheduler, which points
to an object providing the scheduler interface: run\_thread, info, idle\_time.






\section{Goal Workload}

* CPU bound: While (1)
$* Memory bound: while (1) read_random_sequential_memory ()$

\end {comment}

\cleardoublepage

%%% Local Variables:
%%% TeX-master: "diplom"
%%% End:
