% vim:set ft=tex:
\chapter{Future Work}
\label{sec:futurework}

\newglossaryentry{arm}{name=ARM\textregistered{},
description={ARM\textregistered{}} }

After evaluating the benefits and constraints of behaviour-aware load
balancing, I present different opportunities for improvements.
This thesis provides a basis for further experiments, be it to improve
isolation between task groups, expansion to multi-socket systems, or
heterogeneous architectures.

\paragraph{Precise Event Based Sampling}
PEBS allows the user to register an interrupt coupled to a specific counter.
If the counter is increased by an event or overflows, the interrupt triggers
and allows to read the hardware state from a prespecified memory region.
This feature helps a developer to pinpoint, for example memory accesses which
resulted in a cache miss.

PEBS overflow interrupt could eliminate the overflow check in the thread
accounting code path of the kernel.
The interrupt handler must then increase the account of the currently running
thread.

\paragraph{\gls{intel} Cache Allocation Technology (CAT)}
The most promising improvement is CAT\footnote{
  \url{http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/cache-allocation-technology-white-paper.pdf}}.
It allows the user to partition the \gls{llc} or, more precisely to decide
which core is able to write to which cache lines in the \gls{llc}.
However, the core can still read the whole cache.
This feature allows to configure the system, such that security or latency
critical applications run on a exclusive core, which uses a portion of the
\gls{llc} no other core has write access to.
Only the core with write access to this memory area can evict cache lines.

I expect this feature to eliminate the cache as a side-channel for PRIME+PROBE
attacks.
Even if the attacker application runs on the same processor and shares the same
\gls{llc}, it cannot write to the attacked memory.
Also, real-time applications can now rely on a set of cache lines being
present, if the application does not evict the lines itself.

The load balancer presented in  this thesis can now not only provide temporal
separation, with the help of CAT it can also provide spatial isolation on
shared hardware.

However, this hardware feature is currently only present in Broadwell or later
generation Xeon Server CPUs.

\paragraph{Cache Monitoring Technology (CMT)}
CMT allows the monitoring of individual or a group of threads, applications, or
virtual machines by using a resource monitoring ID (RMID)
\footnote{
  \url{https://software.intel.com/en-us/blogs/2014/12/11/intel-s-cache-monitoring-technology-software-visible-interfaces}}.
It monitors the cache usage of the all object with the same RMID and provides
the values via control and data MSRs.
As this feature measures actual cache usage, I expect it to provide better
information for spatial balancing than \gls{llc} misses, but they still
indicate the load on prefetchers and memory interface, which is not covered by
CMT.

However, this feature is only available in Haswell or later generation
Xeon Server CPUs.

\paragraph{Multi-socket systems}
Besides CAT, usage of multi-socket systems can also prevent PRIME+PROBE attacks
or provide a real-time task group with an environment with less interferences.
Currently, the load balancer does not support multiple sockets.
First, the CPUID based topology analysis must be extended to support multiple
packages and second, the CoreAccounting must be adapted to use this new
topology.

\paragraph{Heterogeneous Architectures}
A more complex extension is the support for heterogeneous architectures, like
\gls{arm} big.LITTLE.
\citeauthor{sarma_smartbalance_2015} (\cite{sarma_smartbalance_2015}) use a
predefined matrix to predict the performance change to an application,
if it is migrated to another core type.
But the authors do not consider communication or isolation realtionships.
These groups raise numerous questions: Which core type do isolation groups
need?
If an isolation group is migrated to another core type, how large is the impact
to the rest of the system?
Which core type uses a server with multiple distributed clients?

The energy consumption is also very different compared to a x86 system.
If performance per watt is important, is it better to run \texttt{distr} groups
on the small core type?


\paragraph{Behaviour Categories}
An approach I did not explore during this work are behaviour categories.
Consider four categories: very high \gls{mpc}, high \gls{mpc}, low \gls{mpc},
very low \gls{mpc}.
Each thread belongs to one category and the algorithm selects threads of
different categories to run together on one core.
The assignment of threads to categories could also take a behaviour history
into account and categorize the thread regarding its general behaviour.

I also expect behaviour categories to help decide on difficult questions
arising from heterogeneous architectures.

\paragraph{Hierarchy of Load Balancers}
I discussed hierarchical load balancing in chapter \ref{design:balancer} and
decided to implement a central component.
The benefit of a central load balancing component is knowledge about more
clients and the underlying hardware architecure.
The additional knowledge allows to provide a better placement and make better
use of available resources, for all clients without isolation requirements.
However, the logic in the central component does not allow to implement a
balancer on top of it, which follows different balancing policies.
Currently, all those decisions would be overruled.
A future project can explore designs allowing a hierarchy of balancers and
their performance.

\begin{comment}
\paragraph{Workload-aware balancing}
The modular approach allows quick replacement and testing of different
algorithms in the various components.
If very specific workloads run on the system, tuned balancing algorithms for
this specific workload can be used to increase the performance of the system.
\end{comment}


\cleardoublepage

%%% Local Variables:
%%% TeX-master: "diplom"
%%% End:
