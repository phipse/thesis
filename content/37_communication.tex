% vim:set ft=tex
\section{Communication}
\label{design:comm}

A less attended behaviour property of threads is communication.
It is difficult to observe which threads are communicating with each other and
how often.
This section explores kernel and user land approaches to acquire this
information static and dynamically.


\paragraph{Communication types}
Two types of communication exist.
\citeauthor{hofmeyr_load_2010} assumed a program running several threads which
compute a chunk of work and then communicate their results to each other.
This cycle repeats until all work is executed, where the time executed is the
major part of the cycle and only a small part is used for communication.
Nevertheless, the overall program performance is best, if each thread reaches
the communication synchronisation at the same time to spend as little time as
possible waiting for others.
This connection was also note in \cite{hofmeyr_load_2010}.
The compute-communicate pattern is typical for distributed systems and is named
distributed communication in the following.

The other type is client-server communication.
To achieve the best possible performance, the communication latency, meaning
the time difference between sending and receiving the message, must be minimal.
The latency is minimal, if both communication partners are on the same core.
Additionally, time slice donation, where the server executes on the time slice
of the client, is only possible if both execute on the same core.
Furthermore, the server will not execute unless it has a client request, so a
server typically has long idle times.
Therefore, it is preferable to execute both communication partners on the same
core.

But this conclusion is wrong, if there are several clients of the same task.
If the task runs several threads, then it most likely wants these threads to
execute in parallel.
Running all threads close to the server on the same core, would heavily impact
their performance.
In the worst case, the performance drops below single threaded performance, due
to context switch overhead.

The same argumentation applies, if the server has a high number of clients from
different tasks.
To execute all clients on the server's core, would be a waste of resources.
Hence, the distribution of the tasks threads to different cores takes priority
over low communication latencies.


\subsection{Kernel}
Naturally, acquiring information at kernel level is easier, as more information
context is available.
But leakage of kernel information to user land must be pondered carefully.
Hence, the following approaches are marked as debug feature.


\paragraph{Communication Matrix}
Of interest are communication partners and the rate of communication during a
time frame.
It is important to reduce the latency of intense connections.
To model the communication relationships, each thread is assigned a global
identifier and a matrix is created, where each field contains a counter,
counting each communication event, between the two corresponding global IDs.
This matrix is symmetric, hence to save memory, only the upper half is used
and communication between two threads uses the counter in field
(lowerID, higherID).
The upper bound for the memory requirement is $1/2 * (\#threads)^2$.
As not all threads will communicate with each other, usage of a sparse matrix
will further lower the memory requirement.
A sparse matrix allocates only memory for fields, which are actually used.

\paragraph{Map}
Another approach can be a thread local map, which contains the global
identifier of the communication partner and a counter.
Each communication attempt increases the counter by one.
Similar to the sparse matrix, this approach only allocates memory for used
counters.
Also, the used memory is directly accounted to the threads which needs it.
However, as this is a thread local solution, both communication partners will
maintain their separate counters.
\\

The user land load balancer can use the system call interface to query
and reset these counters.
The answer can contain an array of all counters for this thread, to reduce the
system call overhead.
In case of the matrix, the answer must be created from the thread ID column and
the thread ID row.


\subsection{User land}
At user level, information gathering is much more complicated.
The strong isolation guarantees make it infeasible to work with global
identifiers across all threads.
But comparable capabilities already provide an identifier.

\paragraph{Cooperative communication capabilities}
To communicate with a partner, a thread needs a capability in its own
capability table, pointing to the receiver.
Together with a counter value, this capability can be passed to the load
balancer and the load balancer can then identify communication partners
by comparing this received capability, with the capabilities of the threads
it balances.
The kernel provides a system call which tells, if two passed capabilities point
to the same object.
The load balance can then build a relationship graph between threads and adapt
its assignment.

This approach requires changes to the scheduler interface in L4Re and
cooperating threads.
But it has the benefit, that each thread can decide on its own, if the
communication relationship is intense enough to benefit from increased
locality.
Unfortunately, this requires changes to each thread managed by the balancer and
regular intensity updates, which itself adds communication overhead.
Together with the interface changes, this dynamic approach is deemed infeasible
for this project.

\paragraph{Configuration parameter}
Less invasive, but static, is the usage of task specific configuration parameters.
The two communication types yield two configuration parameters to represent the
different behaviours.
Together with an identifier thread groups can be configured.
This extends the set of isolation parameters for the thread configuration
introduced in \ref{design:isolation}.

This approach requires careful system design, but no change of program source
code or thread cooperation.

\paragraph{Implementation}
The two communication types are named ``DISTR'' and ``CLSVR''.
A group is identified via ``<name>'' and either distributed or clustered.
To identify the server in the client-server relationship, the server task's
group name is assigned the ``\_S'' postfix.
Client tasks use the ``\_C'' postfix.

\begin{lstlisting}
  DISTR = <Name>
  CLSVR = <Name>_{C|S}
\end{lstlisting}

These parameters are optional and are used in the startup script interpreted by
Ned.
