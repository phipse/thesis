\chapter{Technical Background}
\label{sec:state}

% Hier werden zwei wesentliche Aufgaben erledigt:

% 1. Der Leser muß alles beigebracht bekommen, was er zum Verständnis
% der späteren Kapitel braucht. Insbesondere sind in unserem Fach die
% Systemvoraussetzungen zu klären, die man später benutzt. Zulässig ist
% auch, daß man hier auf Tutorials oder Ähnliches verweist, die hier auf
% dem Netz zugänglich sind.

% 2. Es muß klar werden, was anderswo zu diesem Problem gearbeitet
% wird. Insbesondere sollen natürlich die Lücken der anderen klar
% werden. Warum ist die eigene Arbeit, der eigene Ansatz wichtig, um
% hier den Stand der Technik weiterzubringen? Dieses Kapitel wird von
% vielen Lesern übergangen (nicht aber vom Gutachter ;-), auch später
% bei Veröffentlichungen ist "Related Work" eine wichtige Sache.

% Viele Leser stellen dann später fest, daß sie einige der Grundlagen
% doch brauchen und blättern zurück. Deshalb ist es gut,
% Rückwärtsverweise in späteren Kapiteln zu haben, und zwar so, daß man
% die Abschnitte, auf die verwiesen wird, auch für sich lesen
% kann. Diese Kapitel kann relativ lang werden, je größer der Kontext
% der Arbeit, desto länger. Es lohnt sich auch! Den Text kann man unter
% Umständen wiederverwenden, indem man ihn als "Tutorial" zu einem
% Gebiet auch dem Netz zugänglich macht.

% Dadurch gewinnt man manchmal wertvolle Hinweise von Kollegen. Dieses
% Kapitel wird in der Regel zuerst geschrieben und ist das Einfachste
% (oder das Schwerste weil erste).

\ldots state of the art \ldots

\todo{write state}

This chapter will introduce the reader to the necessary basics to understand
this thesis and also provide an overview over the work of other authors in this
research area.

\section{Terminology}

\newacronym{ht}{HT}{Hyper-threadding}
\newacronym{cmp}{CMP}{Chip multiprocessor}
\newacronym{smp}{SMP}{Symmetric multiprocessor}
\newacronym{intel}{INTEL\textregistered}{INTEL\textregistered{}}

\begin{description}
  \item[Thread]
  \item[Task]
  \item[Cache]
  \item[Migration]
  \item[\gls{ht}] \gls{ht} is a technique used by \gls{intel}, which provides
    two logical hardware threads on one physical core.
    The idea behind this technique is to improve the utilization of the
    hardware resources, by multiplexing two threads.
    However, the performance improvements are around 10\% compared to disabled
    \gls{ht}.
  \item[\gls{cmp}] \gls{cmp}
  \item[\gls{smp}] \gls{smp}
\end{description}



\section{Related Work}
\begin{comment}
  Structure for the description of related work:
    * Assumptions
    * Concept
    * Relevant contribution
    * Result
    * Deficits
\end{comment}

\paragraph{ \cite{sarma_smartbalance_2015} } \citeauthor{sarma_smartbalance_2015}
write about their approach to balance work in a heterogeneous system.
They assume a system with a single ISA and several CPUs with different performance
characteristics and different hardware features.
They introduce categories for each performance level and measure the
performance differences between each level.
This results in a matrix displaying the performance gain or degradation, when
a work package (e.g. thread) is migrated.
Their load balancing algorithm has three phases: sense, predict, balance.
During the sense phase the algorithm observes the CPU utilization for an epoch.
An epoch consists of configurable many clock ticks.
The sense-result is then used by the prediction phase to compute a load
expectation for the different performance levels.
Based on this forecast a balancing decision is made and enforced in the third
phase.
Their model can also select the best CPU size for a optimal performance per
joule ratio.


They make use of gem5\footnote{gem5 url}, a cycle accurate hardware simulator,
as besides the ARM big.LITTLE\footnote{ARM big.LITTLE} architecture no
hardware is available, which features more than two CPU sizes.


\paragraph{ \cite{hofmeyr_load_2010} }

\paragraph{ \cite{cruz_dynamic_2014} }

\paragraph{ \cite{zhuravlev_survey_2012} } \citeauthor{zhuravlev_survey_2012}
provide a survey over scheduling techniques, aiming at better usage of shared
resources in multicore processors.
They focus on chip multicore processors (CMPs), which share caches between at
least two cores, but not between all cores.
Techniques like hyper-threading are also taken into account.
Simultaneous multiprocessors (SMPs) are not in the focus of their survey.
INTELs newer architectures, e.g. Haswell, is a SMP architecture, where each
physical core has dedicated L1 \& L2 caches, but the L3 cache is shared between
all cores.
Their algorithmic focus lies on contention-aware schedulers, which consists of
four building blocks: objective, prediction, decision \& enforcement.



\paragraph{ \cite{knauerhase_using_2008} }
\paragraph{ \cite{yarom_recovering_2014} }
\paragraph{ \cite{bernstein_cache-timing_2005} }
\paragraph{ \cite{eyerman_probabilistic_2010} }
\paragraph{ \cite{fedorova_managing_2010} }
\paragraph{ \cite{zhuravlev_addressing_2010} }
\paragraph{ \cite{liu_last-level_2015} }

\cleardoublepage

%%% Local Variables:
%%% TeX-master: "diplom"
%%% End:
